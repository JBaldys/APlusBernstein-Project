{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pred_data_dir' from 'src.constants' (/Users/qiushi/workspace/dsi-courses/APlusBernstein-Project/src/constants.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/qiushi/workspace/dsi-courses/APlusBernstein-Project/notebooks/models/rnn.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qiushi/workspace/dsi-courses/APlusBernstein-Project/notebooks/models/rnn.ipynb#ch0000000?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequence\u001b[39;00m \u001b[39mimport\u001b[39;00m TimeseriesGenerator\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qiushi/workspace/dsi-courses/APlusBernstein-Project/notebooks/models/rnn.ipynb#ch0000000?line=14'>15</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39mstr\u001b[39m(Path(\u001b[39m\"\u001b[39m\u001b[39m../..\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mresolve()))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/qiushi/workspace/dsi-courses/APlusBernstein-Project/notebooks/models/rnn.ipynb#ch0000000?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m model_data_dir, pred_data_dir\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qiushi/workspace/dsi-courses/APlusBernstein-Project/notebooks/models/rnn.ipynb#ch0000000?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m use_target\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pred_data_dir' from 'src.constants' (/Users/qiushi/workspace/dsi-courses/APlusBernstein-Project/src/constants.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import keras\n",
    "import math \n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM, Dense, Dropout, LeakyReLU, GRU, BatchNormalization, Input, LayerNormalization\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow_addons as tfa\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "sys.path.append(str(Path(\"../..\").resolve()))\n",
    "from src.constants import model_data_dir, pred_data_dir\n",
    "from src.utils import use_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(model_data_dir / \"train_classification.csv\")\n",
    "df_test = pd.read_csv(model_data_dir / \"test_classification.csv\")\n",
    "test_dates = pd.to_datetime(df_test[\"date\"])\n",
    "df_train = df_train.drop(columns=[\"date\"])\n",
    "df_test = df_test.drop(\"date\", axis=1)\n",
    "df_train = df_train.loc[:, ~df_train.columns.str.contains(\"_mv_\")]\n",
    "df_test = df_test.loc[:, ~df_test.columns.str.contains(\"_mv_\")]\n",
    "df_train = pd.get_dummies(df_train.astype({\n",
    "    \"month\": \"category\",\n",
    "    \"weekday\": \"category\",\n",
    "    \"day\": \"category\",\n",
    "}), drop_first=True)\n",
    "df_test = pd.get_dummies(df_test.astype({\n",
    "    \"month\": \"category\",\n",
    "    \"weekday\": \"category\",\n",
    "    \"day\": \"category\",\n",
    "}), drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_length = 40\n",
    "batch_size = 10\n",
    "num_features = df_train.shape[1] - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(win_length, num_features)))\n",
    "model.add(LSTM(64, return_sequences=True, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(LSTM(32, return_sequences=False, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=l1_l2(1e-4, 2e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"loss\",\n",
    "                           patience = 5)\n",
    "\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "# lr and wd can be a function or a tensor\n",
    "lr = 1e-1 * schedule(step)\n",
    "wd = lambda: 1e-4 * schedule(step)\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=tfa.optimizers.SGDW(\n",
    "              learning_rate=lr, \n",
    "              weight_decay=wd, \n",
    "              momentum=0.9),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_size, x_train_size = use_target(df_train, \"sc_1d_fwd_rel_d\", \"classification\")\n",
    "y_test_size, x_test_size = use_target(df_test, \"sc_1d_fwd_rel_d\", \"classification\")\n",
    "\n",
    "train_generator_size = TimeseriesGenerator(x_train_size, y_train_size, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator_size = TimeseriesGenerator(x_test_size, y_test_size, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "334/334 [==============================] - 7s 22ms/step - loss: 0.6985 - accuracy: 0.5082 - val_loss: 0.6965 - val_accuracy: 0.4865\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 7s 21ms/step - loss: 0.6989 - accuracy: 0.5100 - val_loss: 0.6965 - val_accuracy: 0.4865\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.6988 - accuracy: 0.5100 - val_loss: 0.6965 - val_accuracy: 0.4865\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.6988 - accuracy: 0.5100 - val_loss: 0.6965 - val_accuracy: 0.4865\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator_size, \n",
    "                    epochs=20,\n",
    "                    validation_data=test_generator_size,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.490249187432286"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_preds = np.where(model.predict(test_generator_size).flatten() > 0.5, 1, 0)\n",
    "true = y_test_size[0:len(y_test_size) - win_length ]\n",
    "np.mean(np.where(size_preds > 0.5, 1, 0) == true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mom, x_train_mom = use_target(df_train, \"mom_1d_fwd_rel_d\", \"classification\")\n",
    "y_test_mom, x_test_mom = use_target(df_test, \"mom_1d_fwd_rel_d\", \"classification\")\n",
    "\n",
    "train_generator_mom = TimeseriesGenerator(x_train_mom, y_train_mom, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator_mom = TimeseriesGenerator(x_test_mom, y_test_mom, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(win_length, num_features)))\n",
    "model.add(LSTM(64, return_sequences=True, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(LSTM(32, return_sequences=False, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=l1_l2(1e-4, 2e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"loss\",\n",
    "                           patience = 5)\n",
    "\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "# lr and wd can be a function or a tensor\n",
    "lr = 1e-1 * schedule(step)\n",
    "wd = lambda: 1e-4 * schedule(step)\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=tfa.optimizers.SGDW(\n",
    "              learning_rate=lr, \n",
    "              weight_decay=wd, \n",
    "              momentum=0.9),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7354 - accuracy: 0.5142 - val_loss: 0.7189 - val_accuracy: 0.5417\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7214 - accuracy: 0.5199 - val_loss: 0.7093 - val_accuracy: 0.5417\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 7s 21ms/step - loss: 0.7156 - accuracy: 0.5250 - val_loss: 0.7042 - val_accuracy: 0.5417\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7100 - accuracy: 0.5181 - val_loss: 0.7007 - val_accuracy: 0.5417\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7096 - accuracy: 0.5136 - val_loss: 0.6999 - val_accuracy: 0.5417\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7049 - accuracy: 0.5262 - val_loss: 0.6970 - val_accuracy: 0.5417\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 7s 19ms/step - loss: 0.7061 - accuracy: 0.5178 - val_loss: 0.7008 - val_accuracy: 0.5417\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7067 - accuracy: 0.5217 - val_loss: 0.6957 - val_accuracy: 0.5417\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7024 - accuracy: 0.5214 - val_loss: 0.6943 - val_accuracy: 0.5417\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7001 - accuracy: 0.5244 - val_loss: 0.6932 - val_accuracy: 0.5417\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.6991 - accuracy: 0.5220 - val_loss: 0.6926 - val_accuracy: 0.5417\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.6985 - accuracy: 0.5271 - val_loss: 0.6921 - val_accuracy: 0.5417\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.6982 - accuracy: 0.5274 - val_loss: 0.6918 - val_accuracy: 0.5417\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.6979 - accuracy: 0.5274 - val_loss: 0.6916 - val_accuracy: 0.5417\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.6977 - accuracy: 0.5274 - val_loss: 0.6915 - val_accuracy: 0.5417\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.6976 - accuracy: 0.5274 - val_loss: 0.6913 - val_accuracy: 0.5417\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.6975 - accuracy: 0.5274 - val_loss: 0.6913 - val_accuracy: 0.5417\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.6974 - accuracy: 0.5274 - val_loss: 0.6912 - val_accuracy: 0.5417\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.6974 - accuracy: 0.5274 - val_loss: 0.6912 - val_accuracy: 0.5417\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.6974 - accuracy: 0.5268 - val_loss: 0.6912 - val_accuracy: 0.5417\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator_mom, \n",
    "                    epochs=20,\n",
    "                    validation_data=test_generator_mom,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5449620801733478"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mom_preds = np.where(model.predict(test_generator_mom).flatten(), 1, 0)\n",
    "true = y_test_mom[0:len(y_test_mom) - win_length ]\n",
    "np.mean(mom_preds == true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_value, x_train_value = use_target(df_train, \"value_1d_fwd_rel_d\", \"classification\")\n",
    "y_test_value, x_test_value = use_target(df_test, \"value_1d_fwd_rel_d\", \"classification\")\n",
    "\n",
    "train_generator_value = TimeseriesGenerator(x_train_value, y_train_value, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator_value = TimeseriesGenerator(x_test_value, y_test_value, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(win_length, num_features)))\n",
    "model.add(LSTM(64, return_sequences=True, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(LSTM(32, return_sequences=False, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=l1_l2(1e-4, 2e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"loss\",\n",
    "                           patience = 5)\n",
    "\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "# lr and wd can be a function or a tensor\n",
    "lr = 1e-1 * schedule(step)\n",
    "wd = lambda: 1e-4 * schedule(step)\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=tfa.optimizers.SGDW(\n",
    "              learning_rate=lr, \n",
    "              weight_decay=wd, \n",
    "              momentum=0.9),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "334/334 [==============================] - 15s 27ms/step - loss: 1.0929 - accuracy: 0.5136 - val_loss: 0.9539 - val_accuracy: 0.5423\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 7s 21ms/step - loss: 0.8994 - accuracy: 0.5109 - val_loss: 0.8318 - val_accuracy: 0.5417\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 7s 21ms/step - loss: 0.7996 - accuracy: 0.5109 - val_loss: 0.7619 - val_accuracy: 0.5417\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.7507 - accuracy: 0.5274 - val_loss: 0.7319 - val_accuracy: 0.5417\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.7311 - accuracy: 0.5250 - val_loss: 0.7188 - val_accuracy: 0.5417\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7206 - accuracy: 0.5271 - val_loss: 0.7101 - val_accuracy: 0.5417\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.7140 - accuracy: 0.5229 - val_loss: 0.7047 - val_accuracy: 0.5417\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.7090 - accuracy: 0.5271 - val_loss: 0.7011 - val_accuracy: 0.5417\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7060 - accuracy: 0.5262 - val_loss: 0.6986 - val_accuracy: 0.5417\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7043 - accuracy: 0.5262 - val_loss: 0.6971 - val_accuracy: 0.5417\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7048 - accuracy: 0.5223 - val_loss: 0.6997 - val_accuracy: 0.5417\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.7051 - accuracy: 0.5271 - val_loss: 0.6996 - val_accuracy: 0.5417\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7025 - accuracy: 0.5235 - val_loss: 0.6950 - val_accuracy: 0.5417\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7002 - accuracy: 0.5250 - val_loss: 0.6934 - val_accuracy: 0.5417\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7027 - accuracy: 0.5238 - val_loss: 0.6980 - val_accuracy: 0.5417\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.7010 - accuracy: 0.5271 - val_loss: 0.6934 - val_accuracy: 0.5417\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.6991 - accuracy: 0.5271 - val_loss: 0.6925 - val_accuracy: 0.5417\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.6984 - accuracy: 0.5274 - val_loss: 0.6920 - val_accuracy: 0.5417\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.6980 - accuracy: 0.5310 - val_loss: 0.6951 - val_accuracy: 0.5417\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.6981 - accuracy: 0.5274 - val_loss: 0.6916 - val_accuracy: 0.5417\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator_mom, \n",
    "                    epochs=20,\n",
    "                    validation_data=test_generator_mom,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4886240520043337"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_preds = np.where(model.predict(test_generator_value).flatten() > 0.5, 1, 0)\n",
    "true = y_test_value[0:len(y_test_value) - win_length ]\n",
    "np.mean(value_preds == true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sc</th>\n",
       "      <th>mom</th>\n",
       "      <th>value</th>\n",
       "      <th>.pred_sc_lstm</th>\n",
       "      <th>.pred_mom_lstm</th>\n",
       "      <th>.pred_value_lstm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1846 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sc  mom  value  .pred_sc_lstm  .pred_mom_lstm  .pred_value_lstm\n",
       "0      1    0      1              1               1                 1\n",
       "1      0    0      1              1               1                 1\n",
       "2      1    1      1              1               1                 1\n",
       "3      1    1      1              1               1                 1\n",
       "4      0    1      1              1               1                 1\n",
       "...   ..  ...    ...            ...             ...               ...\n",
       "1841   1    0      0              1               1                 1\n",
       "1842   0    0      0              1               1                 1\n",
       "1843   0    0      0              1               1                 1\n",
       "1844   1    0      1              1               1                 1\n",
       "1845   0    0      1              1               1                 1\n",
       "\n",
       "[1846 rows x 6 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = df_test.shape[0]\n",
    "\n",
    "lstm_preds = pd.DataFrame({\n",
    "    \"sc\": df_test[\"sc_1d_fwd_rel_d\"][:rows-win_length], \n",
    "    \"mom\": df_test[\"mom_1d_fwd_rel_d\"][:rows-win_length],\n",
    "    \"value\": df_test[\"value_1d_fwd_rel_d\"][:rows-win_length],\n",
    "    \".pred_sc_lstm\": size_preds,\n",
    "    \".pred_mom_lstm\": mom_preds,\n",
    "    \".pred_value_lstm\": value_preds\n",
    "})\n",
    "\n",
    "lstm_preds.to_csv(model_data_dir / \"lstm_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb74c8d9ad66af7fcab0b82fb03282332e8e98e671d4c74408809bf0c7d3f73d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
