{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import keras\n",
    "import math \n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM, Dense, Dropout, LeakyReLU, GRU, BatchNormalization, Input, LayerNormalization\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow_addons as tfa\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "sys.path.append(str(Path(\"../..\").resolve()))\n",
    "from src.constants import model_data_dir, data_dir, raw_data_dir, raw_data_name\n",
    "from src.utils import use_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(model_data_dir / \"train_classification.csv\")\n",
    "df_test = pd.read_csv(model_data_dir / \"test_classification.csv\")\n",
    "test_dates = pd.to_datetime(df_test[\"date\"])\n",
    "df_train = df_train.drop(columns=[\"date\"])\n",
    "df_test = df_test.drop(\"date\", axis=1)\n",
    "df_train = df_train.loc[:, ~df_train.columns.str.contains(\"_mv_\")]\n",
    "df_test = df_test.loc[:, ~df_test.columns.str.contains(\"_mv_\")]\n",
    "df_train = pd.get_dummies(df_train.astype({\n",
    "    \"month\": \"category\",\n",
    "    \"weekday\": \"category\",\n",
    "    \"day\": \"category\",\n",
    "}), drop_first=True)\n",
    "df_test = pd.get_dummies(df_test.astype({\n",
    "    \"month\": \"category\",\n",
    "    \"weekday\": \"category\",\n",
    "    \"day\": \"category\",\n",
    "}), drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_length = 40\n",
    "batch_size = 10\n",
    "num_features = df_train.shape[1] - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(win_length, num_features)))\n",
    "# model.add(LSTM(64, return_sequences=True, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "# model.add(LeakyReLU(alpha=0.5)) \n",
    "# model.add(LayerNormalization())\n",
    "# model.add(Dropout(0.3)) \n",
    "model.add(LSTM(20, return_sequences=False, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=l1_l2(1e-4, 2e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"loss\",\n",
    "                           patience = 5)\n",
    "\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "# lr and wd can be a function or a tensor\n",
    "lr = 1e-5 * schedule(step)\n",
    "wd = lambda: 1e-4 * schedule(step)\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "            #   optimizer=tfa.optimizers.SGDW(\n",
    "            #   learning_rate=lr, \n",
    "            #   weight_decay=wd, \n",
    "            #   momentum=0.9),\n",
    "              optimizer=tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_size, x_train_size = use_target(df_train, \"sc_1d_fwd_rel_d\", \"classification\")\n",
    "y_test_size, x_test_size = use_target(df_test, \"sc_1d_fwd_rel_d\", \"classification\")\n",
    "\n",
    "train_generator_size = TimeseriesGenerator(x_train_size, y_train_size, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator_size = TimeseriesGenerator(x_test_size, y_test_size, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "334/334 [==============================] - 3s 6ms/step - loss: 1.1353 - accuracy: 0.5112 - val_loss: 0.8746 - val_accuracy: 0.5038\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.9659 - accuracy: 0.5112 - val_loss: 0.8806 - val_accuracy: 0.5049\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.9043 - accuracy: 0.5214 - val_loss: 0.8722 - val_accuracy: 0.5043\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8829 - accuracy: 0.5121 - val_loss: 0.8478 - val_accuracy: 0.4989\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8545 - accuracy: 0.5034 - val_loss: 0.8322 - val_accuracy: 0.4978\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8351 - accuracy: 0.5109 - val_loss: 0.8218 - val_accuracy: 0.5011\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8250 - accuracy: 0.5034 - val_loss: 0.8131 - val_accuracy: 0.5054\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8055 - accuracy: 0.5187 - val_loss: 0.8044 - val_accuracy: 0.5033\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7960 - accuracy: 0.5199 - val_loss: 0.7967 - val_accuracy: 0.5038\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7967 - accuracy: 0.5013 - val_loss: 0.7898 - val_accuracy: 0.5043\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7898 - accuracy: 0.5040 - val_loss: 0.7842 - val_accuracy: 0.5043\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7836 - accuracy: 0.5079 - val_loss: 0.7787 - val_accuracy: 0.5022\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7757 - accuracy: 0.5061 - val_loss: 0.7742 - val_accuracy: 0.4989\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7709 - accuracy: 0.5244 - val_loss: 0.7701 - val_accuracy: 0.5016\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7647 - accuracy: 0.5250 - val_loss: 0.7667 - val_accuracy: 0.5005\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7645 - accuracy: 0.5085 - val_loss: 0.7634 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7616 - accuracy: 0.5082 - val_loss: 0.7601 - val_accuracy: 0.4989\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7568 - accuracy: 0.5130 - val_loss: 0.7571 - val_accuracy: 0.4897\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7541 - accuracy: 0.5163 - val_loss: 0.7543 - val_accuracy: 0.4924\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7506 - accuracy: 0.5247 - val_loss: 0.7517 - val_accuracy: 0.4935\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator_size, \n",
    "                    epochs=20,\n",
    "                    validation_data=test_generator_size,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5005417118093174"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_probs = model.predict(test_generator_size).flatten()\n",
    "size_preds = np.where(size_probs > 0.5, 1, 0)\n",
    "true = y_test_size[0:len(y_test_size) - win_length ]\n",
    "np.mean(np.where(size_preds > 0.5, 1, 0) == true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mom, x_train_mom = use_target(df_train, \"mom_1d_fwd_rel_d\", \"classification\")\n",
    "y_test_mom, x_test_mom = use_target(df_test, \"mom_1d_fwd_rel_d\", \"classification\")\n",
    "\n",
    "train_generator_mom = TimeseriesGenerator(x_train_mom, y_train_mom, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator_mom = TimeseriesGenerator(x_test_mom, y_test_mom, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(win_length, num_features)))\n",
    "model.add(LSTM(20, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=l1_l2(1e-4, 2e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"loss\",\n",
    "                           patience = 5)\n",
    "\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "# lr and wd can be a function or a tensor\n",
    "lr = 1e-5 * schedule(step)\n",
    "wd = lambda: 1e-4 * schedule(step)\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "            #   optimizer=tfa.optimizers.SGDW(\n",
    "            #   learning_rate=lr, \n",
    "            #   weight_decay=wd, \n",
    "            #   momentum=0.9),\n",
    "              optimizer=tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "334/334 [==============================] - 4s 8ms/step - loss: 1.1045 - accuracy: 0.5112 - val_loss: 0.8621 - val_accuracy: 0.5336\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.9603 - accuracy: 0.5064 - val_loss: 0.8436 - val_accuracy: 0.5379\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8999 - accuracy: 0.5001 - val_loss: 0.8330 - val_accuracy: 0.5379\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8802 - accuracy: 0.4933 - val_loss: 0.8233 - val_accuracy: 0.5406\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8500 - accuracy: 0.4990 - val_loss: 0.8163 - val_accuracy: 0.5455\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8372 - accuracy: 0.5100 - val_loss: 0.8094 - val_accuracy: 0.5433\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8219 - accuracy: 0.5118 - val_loss: 0.8024 - val_accuracy: 0.5439\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8178 - accuracy: 0.5040 - val_loss: 0.7959 - val_accuracy: 0.5455\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8047 - accuracy: 0.5097 - val_loss: 0.7902 - val_accuracy: 0.5488\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7946 - accuracy: 0.5241 - val_loss: 0.7845 - val_accuracy: 0.5488\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7934 - accuracy: 0.5091 - val_loss: 0.7802 - val_accuracy: 0.5450\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7855 - accuracy: 0.5058 - val_loss: 0.7756 - val_accuracy: 0.5439\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7728 - accuracy: 0.5238 - val_loss: 0.7713 - val_accuracy: 0.5423\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7756 - accuracy: 0.5055 - val_loss: 0.7682 - val_accuracy: 0.5450\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7719 - accuracy: 0.5106 - val_loss: 0.7641 - val_accuracy: 0.5444\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7663 - accuracy: 0.5145 - val_loss: 0.7605 - val_accuracy: 0.5439\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7610 - accuracy: 0.5310 - val_loss: 0.7574 - val_accuracy: 0.5428\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7578 - accuracy: 0.5316 - val_loss: 0.7545 - val_accuracy: 0.5417\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7572 - accuracy: 0.5100 - val_loss: 0.7515 - val_accuracy: 0.5417\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7546 - accuracy: 0.5112 - val_loss: 0.7488 - val_accuracy: 0.5417\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator_mom, \n",
    "                    epochs=20,\n",
    "                    validation_data=test_generator_mom,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5433369447453954"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mom_probs = model.predict(test_generator_mom).flatten()\n",
    "mom_preds = np.where(mom_probs > 0.5, 1, 0)\n",
    "true = y_test_mom[0:len(y_test_mom) - win_length ]\n",
    "np.mean(mom_preds == true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_value, x_train_value = use_target(df_train, \"value_1d_fwd_rel_d\", \"classification\")\n",
    "y_test_value, x_test_value = use_target(df_test, \"value_1d_fwd_rel_d\", \"classification\")\n",
    "\n",
    "train_generator_value = TimeseriesGenerator(x_train_value, y_train_value, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator_value = TimeseriesGenerator(x_test_value, y_test_value, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(win_length, num_features)))\n",
    "model.add(LSTM(20, return_sequences=False, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=l1_l2(1e-4, 2e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"loss\",\n",
    "                           patience = 5)\n",
    "\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "# lr and wd can be a function or a tensor\n",
    "lr = 1e-5 * schedule(step)\n",
    "wd = lambda: 1e-4 * schedule(step)\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "            #   optimizer=tfa.optimizers.SGDW(\n",
    "            #   learning_rate=lr, \n",
    "            #   weight_decay=wd, \n",
    "            #   momentum=0.9),\n",
    "              optimizer=tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "334/334 [==============================] - 4s 8ms/step - loss: 1.1717 - accuracy: 0.4819 - val_loss: 0.9044 - val_accuracy: 0.5054\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 1.0000 - accuracy: 0.4978 - val_loss: 0.8727 - val_accuracy: 0.5195\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.9329 - accuracy: 0.4906 - val_loss: 0.8507 - val_accuracy: 0.5271\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8841 - accuracy: 0.5001 - val_loss: 0.8347 - val_accuracy: 0.5320\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8590 - accuracy: 0.5013 - val_loss: 0.8210 - val_accuracy: 0.5325\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8382 - accuracy: 0.5043 - val_loss: 0.8099 - val_accuracy: 0.5341\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8381 - accuracy: 0.4999 - val_loss: 0.8013 - val_accuracy: 0.5330\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8134 - accuracy: 0.5163 - val_loss: 0.7938 - val_accuracy: 0.5314\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8122 - accuracy: 0.5049 - val_loss: 0.7879 - val_accuracy: 0.5347\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8020 - accuracy: 0.4981 - val_loss: 0.7821 - val_accuracy: 0.5303\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7939 - accuracy: 0.5076 - val_loss: 0.7778 - val_accuracy: 0.5363\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7846 - accuracy: 0.5055 - val_loss: 0.7736 - val_accuracy: 0.5368\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7775 - accuracy: 0.5220 - val_loss: 0.7696 - val_accuracy: 0.5363\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7779 - accuracy: 0.5142 - val_loss: 0.7661 - val_accuracy: 0.5385\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7685 - accuracy: 0.5121 - val_loss: 0.7627 - val_accuracy: 0.5379\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7676 - accuracy: 0.5061 - val_loss: 0.7597 - val_accuracy: 0.5406\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7619 - accuracy: 0.5094 - val_loss: 0.7567 - val_accuracy: 0.5423\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7581 - accuracy: 0.5253 - val_loss: 0.7539 - val_accuracy: 0.5406\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7566 - accuracy: 0.5130 - val_loss: 0.7512 - val_accuracy: 0.5395\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7508 - accuracy: 0.5337 - val_loss: 0.7486 - val_accuracy: 0.5412\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator_mom, \n",
    "                    epochs=20,\n",
    "                    validation_data=test_generator_mom,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5113759479956663"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_probs = model.predict(test_generator_value).flatten()\n",
    "value_preds = np.where(value_probs > 0.6, 1, 0)\n",
    "true = y_test_value[0:len(y_test_value) - win_length ]\n",
    "np.mean(value_preds == true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.read_excel(raw_data_dir / raw_data_name, sheet_name=1, usecols=[\"Date\", \"S&P 500\"])\n",
    "sp[\"Date\"] = pd.to_datetime(sp[\"Date\"])\n",
    "sp = sp.query(\"Date > '2013-12-31'\").drop(\"Date\", axis=1).pct_change().rename({\"S&P 500\": \"s_&_p_500_ret\"}, axis=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "ret = pd.read_excel(raw_data_dir / raw_data_name, sheet_name=3, usecols=[\"Date\", \"sc_1d_fwd_ret\", \"mom_1d_fwd_ret\", \"value_1d_fwd_ret\"])\n",
    "ret[\"Date\"] = pd.to_datetime(ret[\"Date\"])\n",
    "ret = ret.query(\"Date > '2013-12-31'\").drop(\"Date\",axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df_test.shape[0]\n",
    "\n",
    "\n",
    "preds = pd.DataFrame({\n",
    "    \"sc\": df_test[\"sc_1d_fwd_rel_d\"][:rows-win_length], \n",
    "    \"mom\": df_test[\"mom_1d_fwd_rel_d\"][:rows-win_length],\n",
    "    \"value\": df_test[\"value_1d_fwd_rel_d\"][:rows-win_length],\n",
    "    \".pred_prob_sc_lstm\": size_probs,\n",
    "    \".pred_prob_mom_lstm\": mom_probs,\n",
    "    \".pred_prob_value_lstm\": value_probs, \n",
    "    \".pred_sc_lstm\": size_preds,\n",
    "    \".pred_mom_lstm\": mom_preds,\n",
    "    \".pred_value_lstm\": value_preds,\n",
    "    \"s_&_p_500_ret\": sp.iloc[:sp.shape[0]-win_length-1][\"s_&_p_500_ret\"]\n",
    "})\n",
    "lstm_preds = pd.concat([preds, ret.iloc[:ret.shape[0]-win_length]], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "lstm_preds\n",
    "lstm_preds.to_csv(data_dir / \"pred\" / \"lstm_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = Sequential()\n",
    "model_gru.add(Input(shape=(win_length, num_features)))\n",
    "model_gru.add(GRU(20, return_sequences=True))\n",
    "model_gru.add(Dropout(0.3))\n",
    "model_gru.add(GRU(units=30, return_sequences=True))\n",
    "model_gru.add(GRU(units=30, return_sequences=False))\n",
    "model_gru.add(Dropout(0.3))\n",
    "model_gru.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"loss\",\n",
    "                           patience = 5)\n",
    "\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "# lr and wd can be a function or a tensor\n",
    "lr = 1e-5 * schedule(step)\n",
    "wd = lambda: 1e-4 * schedule(step)\n",
    "model_gru.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "334/334 [==============================] - 9s 19ms/step - loss: 0.7095 - accuracy: 0.4837 - val_loss: 0.7005 - val_accuracy: 0.4599\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.6969 - accuracy: 0.5046 - val_loss: 0.6924 - val_accuracy: 0.5206\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.6965 - accuracy: 0.5085 - val_loss: 0.6903 - val_accuracy: 0.5493\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.6946 - accuracy: 0.5130 - val_loss: 0.6895 - val_accuracy: 0.5444\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.6898 - accuracy: 0.5355 - val_loss: 0.6893 - val_accuracy: 0.5433\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.6918 - accuracy: 0.5301 - val_loss: 0.6893 - val_accuracy: 0.5439\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.6910 - accuracy: 0.5280 - val_loss: 0.6892 - val_accuracy: 0.5428\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.6908 - accuracy: 0.5361 - val_loss: 0.6894 - val_accuracy: 0.5423\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.6904 - accuracy: 0.5388 - val_loss: 0.6894 - val_accuracy: 0.5428\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.6917 - accuracy: 0.5283 - val_loss: 0.6895 - val_accuracy: 0.5417\n"
     ]
    }
   ],
   "source": [
    "history = model_gru.fit(train_generator_mom, \n",
    "                    epochs=20,\n",
    "                    validation_data=test_generator_mom,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5449620801733478"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mom_preds2 = np.where(model_gru.predict(test_generator_mom).flatten(), 1, 0)\n",
    "true = y_test_mom[0:len(y_test_mom) - win_length]\n",
    "np.mean(mom_preds2 == true)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb74c8d9ad66af7fcab0b82fb03282332e8e98e671d4c74408809bf0c7d3f73d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
