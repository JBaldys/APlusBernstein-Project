{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import keras\n",
    "import math \n",
    "from keras.layers import LSTM, Dense, Dropout, LeakyReLU, GRU, BatchNormalization, Input, LayerNormalization\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "sys.path.append(str(Path(\"../..\").resolve()))\n",
    "from src.constants import model_data_dir\n",
    "from src.utils import use_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(model_data_dir / \"train_classification.csv\")\n",
    "df_test = pd.read_csv(model_data_dir / \"test_classification.csv\")\n",
    "test_dates = pd.to_datetime(df_test[\"date\"])\n",
    "df_train = df_train.drop(columns=[\"date\"])\n",
    "df_test = df_test.drop(\"date\", axis=1)\n",
    "df_train = df_train.loc[:, ~df_train.columns.str.contains(\"_mv_\")]\n",
    "df_test = df_test.loc[:, ~df_test.columns.str.contains(\"_mv_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_length = 40\n",
    "batch_size = 120 \n",
    "num_features = df_train.shape[1] - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(win_length, num_features)))\n",
    "model.add(LSTM(64, return_sequences=True, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(LSTM(32, return_sequences=False, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=l1_l2(1e-4, 2e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"val_loss\",\n",
    "                           patience = 5)\n",
    "initial_learning_rate = 0.001\n",
    "\n",
    "def lr_exp_decay(epoch, lr):\n",
    "    k = 0.1\n",
    "    return initial_learning_rate * math.exp(-k*epoch)\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=SGD(learning_rate=initial_learning_rate, momentum=0.2),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_size, x_train_size = use_target(df_train, \"sc_1d_fwd_rel_d\", \"classification\")\n",
    "y_test_size, x_test_size = use_target(df_test, \"sc_1d_fwd_rel_d\", \"classification\")\n",
    "\n",
    "train_generator_size = TimeseriesGenerator(x_train_size, y_train_size, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator_size = TimeseriesGenerator(x_test_size, y_test_size, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 4s 81ms/step - loss: 1.1255 - accuracy: 0.5208 - val_loss: 1.0227 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0009048374180359595.\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 2s 65ms/step - loss: 1.0931 - accuracy: 0.5151 - val_loss: 1.0213 - val_accuracy: 0.5135 - lr: 9.0484e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0008187307530779819.\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 1.0869 - accuracy: 0.5130 - val_loss: 1.0221 - val_accuracy: 0.5135 - lr: 8.1873e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0007408182206817179.\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 2s 71ms/step - loss: 1.0799 - accuracy: 0.5103 - val_loss: 1.0223 - val_accuracy: 0.5135 - lr: 7.4082e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0006703200460356394.\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 2s 73ms/step - loss: 1.0725 - accuracy: 0.5109 - val_loss: 1.0222 - val_accuracy: 0.5135 - lr: 6.7032e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0006065306597126335.\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 2s 73ms/step - loss: 1.0727 - accuracy: 0.5115 - val_loss: 1.0221 - val_accuracy: 0.5135 - lr: 6.0653e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005488116360940264.\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 2s 74ms/step - loss: 1.0749 - accuracy: 0.5109 - val_loss: 1.0220 - val_accuracy: 0.5135 - lr: 5.4881e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator_size, epochs=50,\n",
    "                    validation_data=test_generator_size,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[LearningRateScheduler(lr_exp_decay, verbose=1), early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(test_generator_size).flatten()\n",
    "true = y_test_size[0:len(y_test_size) - 40]\n",
    "np.mean(np.where(preds, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mom, x_train_mom = use_target(df_train, \"mom_1d_fwd_rel_d\", \"classification\")\n",
    "y_test_mom, x_test_mom = use_target(df_test, \"mom_1d_fwd_rel_d\", \"classification\")\n",
    "\n",
    "train_generator_mom = TimeseriesGenerator(x_train_mom, y_train_mom, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator_mom = TimeseriesGenerator(x_test_mom, y_test_mom, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 10s 798ms/step - loss: 0.6984 - accuracy: 0.5011 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0009048374180359595.\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 10s 805ms/step - loss: 0.6985 - accuracy: 0.5005 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 9.0484e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0008187307530779819.\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 11s 816ms/step - loss: 0.6981 - accuracy: 0.4974 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 8.1873e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0007408182206817179.\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 10s 798ms/step - loss: 0.6947 - accuracy: 0.5220 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 7.4082e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0006703200460356394.\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 11s 878ms/step - loss: 0.6956 - accuracy: 0.5060 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 6.7032e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0006065306597126335.\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 11s 893ms/step - loss: 0.6963 - accuracy: 0.5075 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 6.0653e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005488116360940264.\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 10s 777ms/step - loss: 0.6970 - accuracy: 0.4983 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 5.4881e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0004965853037914095.\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 10s 786ms/step - loss: 0.6965 - accuracy: 0.4968 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 4.9659e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0004493289641172216.\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 10s 781ms/step - loss: 0.6941 - accuracy: 0.5158 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 4.4933e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00040656965974059914.\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 11s 829ms/step - loss: 0.6975 - accuracy: 0.4931 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 4.0657e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00036787944117144236.\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 10s 788ms/step - loss: 0.6978 - accuracy: 0.4943 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 3.6788e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.00033287108369807955.\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 11s 825ms/step - loss: 0.6967 - accuracy: 0.5072 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 3.3287e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.00030119421191220205.\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 10s 808ms/step - loss: 0.6960 - accuracy: 0.5032 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 3.0119e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0002725317930340126.\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 10s 796ms/step - loss: 0.6974 - accuracy: 0.4903 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 2.7253e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.00024659696394160646.\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 10s 799ms/step - loss: 0.6985 - accuracy: 0.4958 - val_loss: 0.6889 - val_accuracy: 0.5460 - lr: 2.4660e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.00022313016014842982.\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 12s 923ms/step - loss: 0.6965 - accuracy: 0.5223 - val_loss: 0.6890 - val_accuracy: 0.5460 - lr: 2.2313e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator_mom, epochs=50,\n",
    "                    validation_data=test_generator_mom,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[LearningRateScheduler(lr_exp_decay, verbose=1), early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_value, x_train_value = use_target(df_train, \"value_1d_fwd_rel_d\", \"classification\")\n",
    "y_test_value, x_test_value = use_target(df_test, \"value_1d_fwd_rel_d\", \"classification\")\n",
    "\n",
    "train_generator_value = TimeseriesGenerator(x_train_value, y_train_value, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator_value = TimeseriesGenerator(x_test_value, y_test_value, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 12s 852ms/step - loss: 0.6973 - accuracy: 0.4977 - val_loss: 0.6969 - val_accuracy: 0.4841 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0009048374180359595.\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 12s 966ms/step - loss: 0.6969 - accuracy: 0.4983 - val_loss: 0.6964 - val_accuracy: 0.4841 - lr: 9.0484e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0008187307530779819.\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 12s 948ms/step - loss: 0.6950 - accuracy: 0.5060 - val_loss: 0.6962 - val_accuracy: 0.4841 - lr: 8.1873e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0007408182206817179.\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 11s 887ms/step - loss: 0.6957 - accuracy: 0.5112 - val_loss: 0.6958 - val_accuracy: 0.4841 - lr: 7.4082e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0006703200460356394.\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 11s 850ms/step - loss: 0.6961 - accuracy: 0.5097 - val_loss: 0.6955 - val_accuracy: 0.4841 - lr: 6.7032e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0006065306597126335.\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 11s 893ms/step - loss: 0.6948 - accuracy: 0.5078 - val_loss: 0.6953 - val_accuracy: 0.4841 - lr: 6.0653e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005488116360940264.\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 12s 902ms/step - loss: 0.6947 - accuracy: 0.5125 - val_loss: 0.6951 - val_accuracy: 0.4841 - lr: 5.4881e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0004965853037914095.\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 10s 806ms/step - loss: 0.6952 - accuracy: 0.5106 - val_loss: 0.6949 - val_accuracy: 0.4841 - lr: 4.9659e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0004493289641172216.\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 10s 811ms/step - loss: 0.6960 - accuracy: 0.5023 - val_loss: 0.6947 - val_accuracy: 0.4841 - lr: 4.4933e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00040656965974059914.\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 10s 807ms/step - loss: 0.6930 - accuracy: 0.5260 - val_loss: 0.6945 - val_accuracy: 0.4841 - lr: 4.0657e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00036787944117144236.\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 10s 802ms/step - loss: 0.6939 - accuracy: 0.5045 - val_loss: 0.6944 - val_accuracy: 0.4841 - lr: 3.6788e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.00033287108369807955.\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 10s 800ms/step - loss: 0.6965 - accuracy: 0.5008 - val_loss: 0.6943 - val_accuracy: 0.4841 - lr: 3.3287e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.00030119421191220205.\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 10s 786ms/step - loss: 0.7029 - accuracy: 0.5011 - val_loss: 0.6943 - val_accuracy: 0.4841 - lr: 3.0119e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0002725317930340126.\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 11s 825ms/step - loss: 0.6943 - accuracy: 0.5155 - val_loss: 0.6942 - val_accuracy: 0.4841 - lr: 2.7253e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.00024659696394160646.\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 10s 772ms/step - loss: 0.6937 - accuracy: 0.5121 - val_loss: 0.6941 - val_accuracy: 0.4841 - lr: 2.4660e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.00022313016014842982.\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 10s 806ms/step - loss: 0.6959 - accuracy: 0.5094 - val_loss: 0.6940 - val_accuracy: 0.4841 - lr: 2.2313e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.00020189651799465538.\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 10s 816ms/step - loss: 0.6943 - accuracy: 0.5158 - val_loss: 0.6939 - val_accuracy: 0.4841 - lr: 2.0190e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0001826835240527346.\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 13s 996ms/step - loss: 0.6954 - accuracy: 0.5057 - val_loss: 0.6938 - val_accuracy: 0.4841 - lr: 1.8268e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00016529888822158653.\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 13s 991ms/step - loss: 0.6956 - accuracy: 0.4992 - val_loss: 0.6938 - val_accuracy: 0.4841 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00014956861922263504.\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 11s 855ms/step - loss: 0.6932 - accuracy: 0.5281 - val_loss: 0.6937 - val_accuracy: 0.4841 - lr: 1.4957e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0001353352832366127.\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 10s 807ms/step - loss: 0.6943 - accuracy: 0.5146 - val_loss: 0.6937 - val_accuracy: 0.4841 - lr: 1.3534e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0001224564282529819.\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 10s 770ms/step - loss: 0.6959 - accuracy: 0.5078 - val_loss: 0.6937 - val_accuracy: 0.4841 - lr: 1.2246e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.00011080315836233387.\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 11s 861ms/step - loss: 0.6974 - accuracy: 0.5026 - val_loss: 0.6936 - val_accuracy: 0.4841 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.00010025884372280371.\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.6964 - accuracy: 0.5063 - val_loss: 0.6936 - val_accuracy: 0.4841 - lr: 1.0026e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 9.071795328941248e-05.\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 12s 893ms/step - loss: 0.6942 - accuracy: 0.5149 - val_loss: 0.6936 - val_accuracy: 0.4841 - lr: 9.0718e-05\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 8.20849986238988e-05.\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 10s 799ms/step - loss: 0.6954 - accuracy: 0.4989 - val_loss: 0.6936 - val_accuracy: 0.4841 - lr: 8.2085e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 7.427357821433387e-05.\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 10s 799ms/step - loss: 0.6954 - accuracy: 0.5005 - val_loss: 0.6936 - val_accuracy: 0.4841 - lr: 7.4274e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 6.720551273974975e-05.\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 11s 829ms/step - loss: 0.6946 - accuracy: 0.5094 - val_loss: 0.6936 - val_accuracy: 0.4841 - lr: 6.7206e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 6.0810062625217954e-05.\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 11s 833ms/step - loss: 0.6951 - accuracy: 0.5081 - val_loss: 0.6936 - val_accuracy: 0.4841 - lr: 6.0810e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 5.502322005640721e-05.\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 10s 804ms/step - loss: 0.6950 - accuracy: 0.5103 - val_loss: 0.6936 - val_accuracy: 0.4841 - lr: 5.5023e-05\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 4.9787068367863945e-05.\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 11s 824ms/step - loss: 0.6972 - accuracy: 0.4897 - val_loss: 0.6936 - val_accuracy: 0.4841 - lr: 4.9787e-05\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=SGD(learning_rate=initial_learning_rate, momentum=0.2),\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_generator_value, epochs=50,\n",
    "                    validation_data=test_generator_value,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[LearningRateScheduler(lr_exp_decay, verbose=1), early_stop])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb74c8d9ad66af7fcab0b82fb03282332e8e98e671d4c74408809bf0c7d3f73d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
