{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import keras\n",
    "import math \n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM, Dense, Dropout, LeakyReLU, GRU, BatchNormalization, Input, LayerNormalization\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow_addons as tfa\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "sys.path.append(str(Path(\"../..\").resolve()))\n",
    "from src.constants import model_data_dir, data_dir\n",
    "from src.utils import use_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(model_data_dir / \"train_classification.csv\")\n",
    "df_test = pd.read_csv(model_data_dir / \"test_classification.csv\")\n",
    "test_dates = pd.to_datetime(df_test[\"date\"])\n",
    "df_train = df_train.drop(columns=[\"date\"])\n",
    "df_test = df_test.drop(\"date\", axis=1)\n",
    "df_train = df_train.loc[:, ~df_train.columns.str.contains(\"_mv_\")]\n",
    "df_test = df_test.loc[:, ~df_test.columns.str.contains(\"_mv_\")]\n",
    "df_train = pd.get_dummies(df_train.astype({\n",
    "    \"month\": \"category\",\n",
    "    \"weekday\": \"category\",\n",
    "    \"day\": \"category\",\n",
    "}), drop_first=True)\n",
    "df_test = pd.get_dummies(df_test.astype({\n",
    "    \"month\": \"category\",\n",
    "    \"weekday\": \"category\",\n",
    "    \"day\": \"category\",\n",
    "}), drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_length = 40\n",
    "batch_size = 10\n",
    "num_features = df_train.shape[1] - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(win_length, num_features)))\n",
    "# model.add(LSTM(64, return_sequences=True, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "# model.add(LeakyReLU(alpha=0.5)) \n",
    "# model.add(LayerNormalization())\n",
    "# model.add(Dropout(0.3)) \n",
    "model.add(LSTM(20, return_sequences=False, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=l1_l2(1e-4, 2e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"loss\",\n",
    "                           patience = 5)\n",
    "\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "# lr and wd can be a function or a tensor\n",
    "lr = 1e-5 * schedule(step)\n",
    "wd = lambda: 1e-4 * schedule(step)\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "            #   optimizer=tfa.optimizers.SGDW(\n",
    "            #   learning_rate=lr, \n",
    "            #   weight_decay=wd, \n",
    "            #   momentum=0.9),\n",
    "              optimizer=tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_size, x_train_size = use_target(df_train, \"sc_1d_fwd_rel_d\", \"classification\")\n",
    "y_test_size, x_test_size = use_target(df_test, \"sc_1d_fwd_rel_d\", \"classification\")\n",
    "\n",
    "train_generator_size = TimeseriesGenerator(x_train_size, y_train_size, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator_size = TimeseriesGenerator(x_test_size, y_test_size, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "334/334 [==============================] - 7s 8ms/step - loss: 1.1433 - accuracy: 0.5094 - val_loss: 1.1193 - val_accuracy: 0.5130\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 1.0558 - accuracy: 0.5010 - val_loss: 1.0578 - val_accuracy: 0.5152\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.9912 - accuracy: 0.5010 - val_loss: 1.0083 - val_accuracy: 0.5168\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.9433 - accuracy: 0.5115 - val_loss: 0.9686 - val_accuracy: 0.5163\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.9069 - accuracy: 0.5094 - val_loss: 0.9338 - val_accuracy: 0.5173\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8890 - accuracy: 0.5043 - val_loss: 0.9055 - val_accuracy: 0.5179\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8569 - accuracy: 0.5073 - val_loss: 0.8804 - val_accuracy: 0.5163\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8345 - accuracy: 0.5163 - val_loss: 0.8596 - val_accuracy: 0.5179\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8336 - accuracy: 0.5082 - val_loss: 0.8427 - val_accuracy: 0.5184\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8121 - accuracy: 0.5160 - val_loss: 0.8282 - val_accuracy: 0.5190\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8035 - accuracy: 0.5124 - val_loss: 0.8158 - val_accuracy: 0.5190\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7947 - accuracy: 0.5118 - val_loss: 0.8049 - val_accuracy: 0.5179\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.7881 - accuracy: 0.5181 - val_loss: 0.7957 - val_accuracy: 0.5157\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7804 - accuracy: 0.5244 - val_loss: 0.7883 - val_accuracy: 0.5157\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7713 - accuracy: 0.5259 - val_loss: 0.7813 - val_accuracy: 0.5130\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7708 - accuracy: 0.5070 - val_loss: 0.7750 - val_accuracy: 0.5135\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7655 - accuracy: 0.5112 - val_loss: 0.7693 - val_accuracy: 0.5141\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7611 - accuracy: 0.5091 - val_loss: 0.7646 - val_accuracy: 0.5173\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7563 - accuracy: 0.5193 - val_loss: 0.7601 - val_accuracy: 0.5173\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7547 - accuracy: 0.5166 - val_loss: 0.7564 - val_accuracy: 0.5135\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7533 - accuracy: 0.5079 - val_loss: 0.7527 - val_accuracy: 0.5135\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7475 - accuracy: 0.5304 - val_loss: 0.7496 - val_accuracy: 0.5157\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7447 - accuracy: 0.5280 - val_loss: 0.7466 - val_accuracy: 0.5157\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7425 - accuracy: 0.5205 - val_loss: 0.7439 - val_accuracy: 0.5157\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7402 - accuracy: 0.5259 - val_loss: 0.7415 - val_accuracy: 0.5157\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7375 - accuracy: 0.5202 - val_loss: 0.7392 - val_accuracy: 0.5179\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7349 - accuracy: 0.5349 - val_loss: 0.7369 - val_accuracy: 0.5173\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7336 - accuracy: 0.5406 - val_loss: 0.7349 - val_accuracy: 0.5179\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7312 - accuracy: 0.5334 - val_loss: 0.7329 - val_accuracy: 0.5179\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7291 - accuracy: 0.5328 - val_loss: 0.7310 - val_accuracy: 0.5190\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7263 - accuracy: 0.5457 - val_loss: 0.7292 - val_accuracy: 0.5217\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7252 - accuracy: 0.5397 - val_loss: 0.7275 - val_accuracy: 0.5233\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7237 - accuracy: 0.5388 - val_loss: 0.7258 - val_accuracy: 0.5228\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7226 - accuracy: 0.5403 - val_loss: 0.7242 - val_accuracy: 0.5222\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7207 - accuracy: 0.5394 - val_loss: 0.7227 - val_accuracy: 0.5222\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7197 - accuracy: 0.5364 - val_loss: 0.7211 - val_accuracy: 0.5217\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7189 - accuracy: 0.5325 - val_loss: 0.7197 - val_accuracy: 0.5228\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7166 - accuracy: 0.5403 - val_loss: 0.7183 - val_accuracy: 0.5217\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7146 - accuracy: 0.5490 - val_loss: 0.7170 - val_accuracy: 0.5222\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7142 - accuracy: 0.5448 - val_loss: 0.7157 - val_accuracy: 0.5233\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7124 - accuracy: 0.5430 - val_loss: 0.7145 - val_accuracy: 0.5238\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7112 - accuracy: 0.5529 - val_loss: 0.7134 - val_accuracy: 0.5244\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7105 - accuracy: 0.5439 - val_loss: 0.7122 - val_accuracy: 0.5265\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7091 - accuracy: 0.5499 - val_loss: 0.7111 - val_accuracy: 0.5282\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7082 - accuracy: 0.5400 - val_loss: 0.7100 - val_accuracy: 0.5271\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7069 - accuracy: 0.5448 - val_loss: 0.7090 - val_accuracy: 0.5282\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7062 - accuracy: 0.5487 - val_loss: 0.7080 - val_accuracy: 0.5293\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7049 - accuracy: 0.5487 - val_loss: 0.7070 - val_accuracy: 0.5265\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7044 - accuracy: 0.5481 - val_loss: 0.7060 - val_accuracy: 0.5276\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7030 - accuracy: 0.5427 - val_loss: 0.7052 - val_accuracy: 0.5255\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator_size, \n",
    "                    epochs=50,\n",
    "                    validation_data=test_generator_size,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5173347778981582"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_preds = np.where(model.predict(test_generator_size).flatten() > 0.5, 1, 0)\n",
    "true = y_test_size[0:len(y_test_size) - win_length ]\n",
    "np.mean(np.where(size_preds > 0.5, 1, 0) == true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mom, x_train_mom = use_target(df_train, \"mom_1d_fwd_rel_d\", \"classification\")\n",
    "y_test_mom, x_test_mom = use_target(df_test, \"mom_1d_fwd_rel_d\", \"classification\")\n",
    "\n",
    "train_generator_mom = TimeseriesGenerator(x_train_mom, y_train_mom, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator_mom = TimeseriesGenerator(x_test_mom, y_test_mom, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(win_length, num_features)))\n",
    "model.add(LSTM(20, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=l1_l2(1e-4, 2e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"loss\",\n",
    "                           patience = 5)\n",
    "\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "# lr and wd can be a function or a tensor\n",
    "lr = 1e-5 * schedule(step)\n",
    "wd = lambda: 1e-4 * schedule(step)\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "            #   optimizer=tfa.optimizers.SGDW(\n",
    "            #   learning_rate=lr, \n",
    "            #   weight_decay=wd, \n",
    "            #   momentum=0.9),\n",
    "              optimizer=tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "334/334 [==============================] - 6s 8ms/step - loss: 0.9868 - accuracy: 0.4969 - val_loss: 0.8907 - val_accuracy: 0.5098\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.9485 - accuracy: 0.4909 - val_loss: 0.8702 - val_accuracy: 0.5027\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.9034 - accuracy: 0.5037 - val_loss: 0.8535 - val_accuracy: 0.4984\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8774 - accuracy: 0.5106 - val_loss: 0.8401 - val_accuracy: 0.4940\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8554 - accuracy: 0.5082 - val_loss: 0.8290 - val_accuracy: 0.4962\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8379 - accuracy: 0.5055 - val_loss: 0.8201 - val_accuracy: 0.4924\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8186 - accuracy: 0.5118 - val_loss: 0.8126 - val_accuracy: 0.4913\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8137 - accuracy: 0.5136 - val_loss: 0.8060 - val_accuracy: 0.4913\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8048 - accuracy: 0.5004 - val_loss: 0.8001 - val_accuracy: 0.4892\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7927 - accuracy: 0.5175 - val_loss: 0.7949 - val_accuracy: 0.4908\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7816 - accuracy: 0.5304 - val_loss: 0.7901 - val_accuracy: 0.4870\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7782 - accuracy: 0.5226 - val_loss: 0.7858 - val_accuracy: 0.4881\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7766 - accuracy: 0.5244 - val_loss: 0.7817 - val_accuracy: 0.4810\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7698 - accuracy: 0.5199 - val_loss: 0.7779 - val_accuracy: 0.4827\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7684 - accuracy: 0.5112 - val_loss: 0.7744 - val_accuracy: 0.4783\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7620 - accuracy: 0.5307 - val_loss: 0.7711 - val_accuracy: 0.4680\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7585 - accuracy: 0.5196 - val_loss: 0.7679 - val_accuracy: 0.4707\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7584 - accuracy: 0.5169 - val_loss: 0.7650 - val_accuracy: 0.4686\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7523 - accuracy: 0.5193 - val_loss: 0.7621 - val_accuracy: 0.4588\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7477 - accuracy: 0.5355 - val_loss: 0.7595 - val_accuracy: 0.4577\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7487 - accuracy: 0.5244 - val_loss: 0.7569 - val_accuracy: 0.4561\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7435 - accuracy: 0.5310 - val_loss: 0.7544 - val_accuracy: 0.4540\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7423 - accuracy: 0.5304 - val_loss: 0.7519 - val_accuracy: 0.4550\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7389 - accuracy: 0.5325 - val_loss: 0.7496 - val_accuracy: 0.4594\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7388 - accuracy: 0.5304 - val_loss: 0.7473 - val_accuracy: 0.4518\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7351 - accuracy: 0.5283 - val_loss: 0.7453 - val_accuracy: 0.4512\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7322 - accuracy: 0.5382 - val_loss: 0.7431 - val_accuracy: 0.4550\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7308 - accuracy: 0.5469 - val_loss: 0.7410 - val_accuracy: 0.4572\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7300 - accuracy: 0.5346 - val_loss: 0.7390 - val_accuracy: 0.4686\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7274 - accuracy: 0.5328 - val_loss: 0.7372 - val_accuracy: 0.4637\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7256 - accuracy: 0.5343 - val_loss: 0.7354 - val_accuracy: 0.4610\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7238 - accuracy: 0.5406 - val_loss: 0.7336 - val_accuracy: 0.4610\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7213 - accuracy: 0.5466 - val_loss: 0.7318 - val_accuracy: 0.4605\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7193 - accuracy: 0.5478 - val_loss: 0.7301 - val_accuracy: 0.4605\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7196 - accuracy: 0.5400 - val_loss: 0.7284 - val_accuracy: 0.4632\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7172 - accuracy: 0.5520 - val_loss: 0.7267 - val_accuracy: 0.4642\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7161 - accuracy: 0.5379 - val_loss: 0.7252 - val_accuracy: 0.4642\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7155 - accuracy: 0.5499 - val_loss: 0.7235 - val_accuracy: 0.4637\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7135 - accuracy: 0.5466 - val_loss: 0.7220 - val_accuracy: 0.4642\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7122 - accuracy: 0.5502 - val_loss: 0.7206 - val_accuracy: 0.4653\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.7120 - accuracy: 0.5412 - val_loss: 0.7193 - val_accuracy: 0.4637\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.7098 - accuracy: 0.5508 - val_loss: 0.7180 - val_accuracy: 0.4664\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.7087 - accuracy: 0.5472 - val_loss: 0.7167 - val_accuracy: 0.4664\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.7081 - accuracy: 0.5466 - val_loss: 0.7154 - val_accuracy: 0.4670\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.7064 - accuracy: 0.5454 - val_loss: 0.7141 - val_accuracy: 0.4680\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.7059 - accuracy: 0.5472 - val_loss: 0.7129 - val_accuracy: 0.4675\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7044 - accuracy: 0.5484 - val_loss: 0.7117 - val_accuracy: 0.4664\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.7038 - accuracy: 0.5430 - val_loss: 0.7106 - val_accuracy: 0.4659\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.7029 - accuracy: 0.5493 - val_loss: 0.7095 - val_accuracy: 0.4642\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7018 - accuracy: 0.5505 - val_loss: 0.7085 - val_accuracy: 0.4637\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator_mom, \n",
    "                    epochs=50,\n",
    "                    validation_data=test_generator_mom,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5449620801733478"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mom_preds = np.where(model.predict(test_generator_mom).flatten(), 1, 0)\n",
    "true = y_test_mom[0:len(y_test_mom) - win_length ]\n",
    "np.mean(mom_preds == true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_value, x_train_value = use_target(df_train, \"value_1d_fwd_rel_d\", \"classification\")\n",
    "y_test_value, x_test_value = use_target(df_test, \"value_1d_fwd_rel_d\", \"classification\")\n",
    "\n",
    "train_generator_value = TimeseriesGenerator(x_train_value, y_train_value, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator_value = TimeseriesGenerator(x_test_value, y_test_value, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(win_length, num_features)))\n",
    "model.add(LSTM(20, return_sequences=False, bias_initializer=\"zeros\", unit_forget_bias=True, kernel_regularizer=l1(1e-4), recurrent_regularizer=l2(2e-4)))\n",
    "model.add(LeakyReLU(alpha=0.5)) \n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=l1_l2(1e-4, 2e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"loss\",\n",
    "                           patience = 5)\n",
    "\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "# lr and wd can be a function or a tensor\n",
    "lr = 1e-5 * schedule(step)\n",
    "wd = lambda: 1e-4 * schedule(step)\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "            #   optimizer=tfa.optimizers.SGDW(\n",
    "            #   learning_rate=lr, \n",
    "            #   weight_decay=wd, \n",
    "            #   momentum=0.9),\n",
    "              optimizer=tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "334/334 [==============================] - 6s 9ms/step - loss: 0.9784 - accuracy: 0.5142 - val_loss: 1.0125 - val_accuracy: 0.4670\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.9399 - accuracy: 0.5103 - val_loss: 0.9907 - val_accuracy: 0.4670\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.9096 - accuracy: 0.5055 - val_loss: 0.9695 - val_accuracy: 0.4680\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8938 - accuracy: 0.5103 - val_loss: 0.9508 - val_accuracy: 0.4664\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8767 - accuracy: 0.5043 - val_loss: 0.9337 - val_accuracy: 0.4637\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8573 - accuracy: 0.5127 - val_loss: 0.9181 - val_accuracy: 0.4615\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8386 - accuracy: 0.5106 - val_loss: 0.9032 - val_accuracy: 0.4626\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8188 - accuracy: 0.5256 - val_loss: 0.8887 - val_accuracy: 0.4632\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8178 - accuracy: 0.5064 - val_loss: 0.8753 - val_accuracy: 0.4632\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8036 - accuracy: 0.5151 - val_loss: 0.8636 - val_accuracy: 0.4626\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7946 - accuracy: 0.5202 - val_loss: 0.8522 - val_accuracy: 0.4626\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7921 - accuracy: 0.5124 - val_loss: 0.8423 - val_accuracy: 0.4642\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7769 - accuracy: 0.5295 - val_loss: 0.8327 - val_accuracy: 0.4621\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7804 - accuracy: 0.5175 - val_loss: 0.8240 - val_accuracy: 0.4659\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7741 - accuracy: 0.5148 - val_loss: 0.8164 - val_accuracy: 0.4626\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7641 - accuracy: 0.5307 - val_loss: 0.8086 - val_accuracy: 0.4599\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7652 - accuracy: 0.5112 - val_loss: 0.8012 - val_accuracy: 0.4615\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7595 - accuracy: 0.5154 - val_loss: 0.7953 - val_accuracy: 0.4583\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7537 - accuracy: 0.5289 - val_loss: 0.7897 - val_accuracy: 0.4615\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7511 - accuracy: 0.5310 - val_loss: 0.7837 - val_accuracy: 0.4605\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7488 - accuracy: 0.5265 - val_loss: 0.7785 - val_accuracy: 0.4588\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7468 - accuracy: 0.5325 - val_loss: 0.7738 - val_accuracy: 0.4583\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7453 - accuracy: 0.5235 - val_loss: 0.7697 - val_accuracy: 0.4577\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7401 - accuracy: 0.5397 - val_loss: 0.7653 - val_accuracy: 0.4556\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7378 - accuracy: 0.5409 - val_loss: 0.7614 - val_accuracy: 0.4556\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7347 - accuracy: 0.5430 - val_loss: 0.7577 - val_accuracy: 0.4534\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7332 - accuracy: 0.5361 - val_loss: 0.7541 - val_accuracy: 0.4550\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7309 - accuracy: 0.5523 - val_loss: 0.7514 - val_accuracy: 0.4561\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7302 - accuracy: 0.5511 - val_loss: 0.7484 - val_accuracy: 0.4577\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7281 - accuracy: 0.5505 - val_loss: 0.7456 - val_accuracy: 0.4567\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7272 - accuracy: 0.5247 - val_loss: 0.7428 - val_accuracy: 0.4561\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7247 - accuracy: 0.5298 - val_loss: 0.7402 - val_accuracy: 0.4556\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7237 - accuracy: 0.5307 - val_loss: 0.7377 - val_accuracy: 0.4567\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7219 - accuracy: 0.5370 - val_loss: 0.7355 - val_accuracy: 0.4567\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7195 - accuracy: 0.5544 - val_loss: 0.7333 - val_accuracy: 0.4583\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7177 - accuracy: 0.5484 - val_loss: 0.7313 - val_accuracy: 0.4583\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7168 - accuracy: 0.5511 - val_loss: 0.7294 - val_accuracy: 0.4588\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7157 - accuracy: 0.5496 - val_loss: 0.7275 - val_accuracy: 0.4572\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7148 - accuracy: 0.5391 - val_loss: 0.7257 - val_accuracy: 0.4572\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7132 - accuracy: 0.5538 - val_loss: 0.7241 - val_accuracy: 0.4572\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7123 - accuracy: 0.5505 - val_loss: 0.7225 - val_accuracy: 0.4567\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7111 - accuracy: 0.5439 - val_loss: 0.7208 - val_accuracy: 0.4572\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7098 - accuracy: 0.5493 - val_loss: 0.7194 - val_accuracy: 0.4561\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7082 - accuracy: 0.5615 - val_loss: 0.7179 - val_accuracy: 0.4561\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7068 - accuracy: 0.5493 - val_loss: 0.7165 - val_accuracy: 0.4567\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7066 - accuracy: 0.5508 - val_loss: 0.7152 - val_accuracy: 0.4567\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7056 - accuracy: 0.5514 - val_loss: 0.7140 - val_accuracy: 0.4561\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7049 - accuracy: 0.5472 - val_loss: 0.7128 - val_accuracy: 0.4550\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7039 - accuracy: 0.5559 - val_loss: 0.7115 - val_accuracy: 0.4567\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.7031 - accuracy: 0.5502 - val_loss: 0.7104 - val_accuracy: 0.4572\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator_mom, \n",
    "                    epochs=50,\n",
    "                    validation_data=test_generator_mom,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5092091007583965"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_preds = np.where(model.predict(test_generator_value).flatten() > 0.5, 1, 0)\n",
    "true = y_test_value[0:len(y_test_value) - win_length ]\n",
    "np.mean(value_preds == true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df_test.shape[0]\n",
    "\n",
    "lstm_preds = pd.DataFrame({\n",
    "    \"sc\": df_test[\"sc_1d_fwd_rel_d\"][:rows-win_length], \n",
    "    \"mom\": df_test[\"mom_1d_fwd_rel_d\"][:rows-win_length],\n",
    "    \"value\": df_test[\"value_1d_fwd_rel_d\"][:rows-win_length],\n",
    "    \".pred_sc_lstm\": size_preds,\n",
    "    \".pred_mom_lstm\": mom_preds,\n",
    "    \".pred_value_lstm\": value_preds\n",
    "})\n",
    "\n",
    "lstm_preds.to_csv(data_dir / \"pred\" / \"lstm_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = Sequential()\n",
    "model_gru.add(Input(shape=(win_length, num_features)))\n",
    "model_gru.add(GRU(75, return_sequences=True))\n",
    "model_gru.add(Dropout(0.3))\n",
    "model_gru.add(GRU(units=30, return_sequences=True))\n",
    "model_gru.add(GRU(units=30, return_sequences=False))\n",
    "model_gru.add(Dropout(0.3))\n",
    "model_gru.add(Dense(units=1, activation=\"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"val_loss\",\n",
    "                           patience = 5)\n",
    "\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "# lr and wd can be a function or a tensor\n",
    "lr = 1e-1 * schedule(step)\n",
    "wd = lambda: 1e-4 * schedule(step)\n",
    "model_gru.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=tfa.optimizers.SGDW(\n",
    "              learning_rate=lr, \n",
    "              weight_decay=wd, \n",
    "              momentum=0.9),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "334/334 [==============================] - 18s 29ms/step - loss: 1.0125 - accuracy: 0.4990 - val_loss: 1.0145 - val_accuracy: 0.5417\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 8s 24ms/step - loss: 1.0810 - accuracy: 0.4900 - val_loss: 0.7528 - val_accuracy: 0.5401\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 9s 26ms/step - loss: 1.0195 - accuracy: 0.5079 - val_loss: 0.7475 - val_accuracy: 0.5049\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 9s 26ms/step - loss: 0.9980 - accuracy: 0.4963 - val_loss: 2.0994 - val_accuracy: 0.4577\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 9s 26ms/step - loss: 1.0542 - accuracy: 0.5028 - val_loss: 1.3836 - val_accuracy: 0.5417\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 9s 26ms/step - loss: 0.9842 - accuracy: 0.5214 - val_loss: 0.7610 - val_accuracy: 0.4572\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 9s 26ms/step - loss: 0.9905 - accuracy: 0.5082 - val_loss: 0.9701 - val_accuracy: 0.4702\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 9s 26ms/step - loss: 0.9699 - accuracy: 0.5055 - val_loss: 1.1025 - val_accuracy: 0.5417\n"
     ]
    }
   ],
   "source": [
    "history = model_gru.fit(train_generator_mom, \n",
    "                    epochs=20,\n",
    "                    validation_data=test_generator_mom,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5449620801733478"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mom_preds = np.where(model_gru.predict(test_generator_mom).flatten(), 1, 0)\n",
    "true = y_test_mom[0:len(y_test_mom) - win_length ]\n",
    "np.mean(mom_preds == true)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb74c8d9ad66af7fcab0b82fb03282332e8e98e671d4c74408809bf0c7d3f73d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
